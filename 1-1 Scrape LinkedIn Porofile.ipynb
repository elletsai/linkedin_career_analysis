{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn Profile Analysis\n",
    "Goal: This project aim to analysis positions description shows on LinkedIn(eg data analyst, data engineer) and incorporate what we found on personal resume\n",
    "\n",
    "1. Scraped data from LinkedIn using web scraping (Beautiful Soup & Selenium)\n",
    "2. Pre-process data\n",
    "3. Exploratory Data Analysis:\n",
    "    - See what verb do people used the most in creating their Resume (First word in every sentence)\n",
    "    - Bigram / Trigram to see what skills or most common words are used in those position\n",
    "    - Verb that used with data related jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-1 Scrape username from LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T23:42:28.266314Z",
     "start_time": "2020-04-12T23:42:28.250887Z"
    }
   },
   "outputs": [],
   "source": [
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm #check for the scarping progress\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from scrape_linkedin import ProfileScraper\n",
    "from selenium.webdriver.common.by import By\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T23:42:32.005359Z",
     "start_time": "2020-04-12T23:42:31.994510Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_name():\n",
    "    # get username\n",
    "    name_list = []\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "#     company = soup.find(class_=\"search-results__list list-style-none \")\n",
    "    \n",
    "    for a in soup.find(class_=\"search-results__list list-style-none\").find_all('a', href=True):\n",
    "        name = a['href'].split('/')[-2]\n",
    "        if a['href'].split('/')[1] == 'in' and name not in name_list:\n",
    "            name_list.append(name)\n",
    "    batch(name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T17:54:22.208643Z",
     "start_time": "2020-04-13T17:54:22.204809Z"
    }
   },
   "outputs": [],
   "source": [
    "# save while scraping\n",
    "import pickle\n",
    "def batch(name):\n",
    "    with open('name_de_v2.pkl', 'ab') as fp:\n",
    "        pickle.dump(name, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T14:56:56.255925Z",
     "start_time": "2020-04-15T14:51:31.252551Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/100 [00:27<44:59, 27.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 2/100 [00:49<42:10, 25.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 3/100 [01:17<42:28, 26.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 4/100 [01:44<42:33, 26.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 5/100 [02:12<42:36, 26.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 6/100 [02:39<42:19, 27.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 7/100 [03:06<42:03, 27.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 8/100 [03:33<41:38, 27.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 9/100 [04:01<41:14, 27.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 10/100 [04:28<40:50, 27.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|█         | 11/100 [04:55<40:30, 27.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-420-032d572f35c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get name by using Beautiful soup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c2e29b34c89d>\u001b[0m in \u001b[0;36mget_name\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"search-results__list list-style-none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'in'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mname_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.linkedin.com/search/results/people/?keywords=Software%20Engineer&origin=SWITCH_SEARCH_VERTICAL&page=53\"\n",
    "driver.get(url)\n",
    "\n",
    "# login linkedin\n",
    "driver.find_element_by_css_selector('body > div > main > p > a').click()\n",
    "time.sleep(0.5)\n",
    "driver.find_element_by_css_selector('input#username').send_keys('yt9mh@virginia.edu') # your email\n",
    "driver.find_element_by_css_selector('input#password').send_keys('lovily85') # your password for linkedin\n",
    "driver.find_element_by_css_selector('#app__container > main > div:nth-child(2) > form > div.login__form_action_container > button').click()\n",
    "\n",
    "for i in tqdm(range(100)): # how many pages do we want to scrape\n",
    "\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") # scroll down and wait website to load\n",
    "    time.sleep(12)\n",
    "\n",
    "    get_name()  # get name by using Beautiful soup\n",
    "    time.sleep(5)\n",
    "\n",
    "    # click on next bottom to go to next page\n",
    "    xpath = '//button[contains(@aria-label,\"Next\")]'\n",
    "    driver.find_element(By.XPATH, xpath).click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get name id from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T17:54:36.500643Z",
     "start_time": "2020-04-13T17:54:36.494881Z"
    }
   },
   "outputs": [],
   "source": [
    "#not need for now\n",
    "# open name.pkl file\n",
    "name = []\n",
    "with open('name_de_v2.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            name.append(pickle.load(fr)) \n",
    "            #pickle.load(fr): pickle.load(file)\n",
    "            #read the object from the file and return the reconstituted object hierarchy specified therein\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "from itertools import chain\n",
    "name_de_v2 = list(chain.from_iterable(name)) #chain thins in different arrays together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T17:54:40.902625Z",
     "start_time": "2020-04-13T17:54:40.897748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1074"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name_de_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T17:54:28.818789Z",
     "start_time": "2020-04-13T17:54:28.814009Z"
    }
   },
   "outputs": [],
   "source": [
    "name_de_tot = list(set(name_de_v2 + name_de))\n",
    "batch(name_de_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T17:57:11.874599Z",
     "start_time": "2020-04-13T17:57:11.866159Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "de = pd.DataFrame(name_de_tot, columns = ['de_name'])\n",
    "de.to_csv('name_de.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T18:07:41.829186Z",
     "start_time": "2020-04-13T18:07:41.820052Z"
    }
   },
   "outputs": [],
   "source": [
    "de = pd.read_csv('name_de.csv')\n",
    "name_de = list(de['de_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use write csv to save by rows\n",
    "'hyunjae-yu' last scrape in data analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T20:19:29.020335Z",
     "start_time": "2020-04-12T20:19:01.748434Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# LI_AT = 'AQEDASqt89oFOYnbAAABcB2vVKkAAAFxeby1ZU0APL5S3jkundKs8NMku9JqGfod9KTZSvenbZTjqIv5LLffYlAmjiNpGiHad6WIlwDbX2-TfVS56hWIcBUB4wW0CZ2y7uIM_BBcikJXup38mpvfiUwA'\n",
    "# elle's\n",
    "LI_AT = 'AQEDASninKgFCQENAAABcWJ8RbkAAAFxhojJuU0ARn_JC06BmSzB8515Xro1AqXinajR4vaRFt5_RFnE1Yc9_6F1VWCAS9BjkPnfqHkirT9j3Mjdb_U0JpJ8EDgfItrqRsndIjAMxyTc0LqheG64WKPJ'\n",
    "\n",
    "# users = ['yuchen-miranda-zhao', 'jamie-yu-3348434b', 'rongxinz', 'ziyi-li-333a21168'] \n",
    "\n",
    "with open('experience.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for name in name_list:\n",
    "        with ProfileScraper(cookie = LI_AT) as scraper:\n",
    "            profile = scraper.scrape(user = name)\n",
    "        for job in profile.experiences['jobs']:\n",
    "            writer.writerow([name, job['title'], job['company'], job['date_range'], job['location'], job['description']])\n",
    "            #print(name, job['title'], job['company'], job['date range'], job['location'], job['description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use following to save simultaneously in two files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T21:05:22.877196Z",
     "start_time": "2020-04-15T21:05:22.871511Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def info_batch(info):\n",
    "    with open('info_de.pkl', 'ab') as fp: \n",
    "        pickle.dump(info, fp) \n",
    "    \n",
    "def exp_batch(exp):\n",
    "    with open('exp_de.pkl', 'ab') as fp:\n",
    "        pickle.dump(exp, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T18:01:02.965129Z",
     "start_time": "2020-04-16T18:01:02.959991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check index \n",
    "name_de.index('subbu-ch-69959943')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T13:53:06.856551Z",
     "start_time": "2020-04-15T13:53:06.852214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1074"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:42:39.390978Z",
     "start_time": "2020-04-18T01:36:37.640491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gayathri-balakumar-6b474978\n",
      "moussa-taifi\n",
      "sree-lakshmi-addepalli\n",
      "yaoquan-eric-ye-059a47142\n",
      "jainsaner\n",
      "akshatism\n",
      "cong-qian-067606149\n",
      "matthew-kravetz-2b27206b\n",
      "paulschnau\n",
      "suhas-ramakrishna-aithal-a9909b29\n",
      "jeffhchuang\n",
      "kal-lemma\n",
      "ravsukhram\n",
      "hemanthbm\n"
     ]
    }
   ],
   "source": [
    "LI_AT = 'AQEDASninKgFGvIZAAABcYQBtfIAAAFxqA458k0ALUoBWM45vLNH8UAZq4A3swR4QAN8gP9j892uDm8wAj1Mvk1z9qGKVedYIEMQ3E--iRBbAqtncGPB6OBGXn5La1px694PRJ246s_2OzHCYckJ0iRD'\n",
    "\n",
    "for name in name_de[1060:]:\n",
    "    with ProfileScraper(cookie = LI_AT) as scraper:\n",
    "        profile = scraper.scrape(user = name)\n",
    "        \n",
    "    # save to info file        \n",
    "    summary = profile.personal_info['summary']\n",
    "    skill = [profile.skills[i]['name'] for i in range(len(profile.skills))]\n",
    "    certi = profile.accomplishments['certifications']\n",
    "    course = profile.accomplishments['courses']\n",
    "\n",
    "    info_batch(tuple([name, summary, skill, course, certi]))\n",
    "    \n",
    "    # save to exp file\n",
    "    for job in profile.experiences['jobs']:\n",
    "        exp_batch(tuple([name, job['title'], job['company'], job['date_range'], job['location'], job['description']]))\n",
    "    print(name)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:53:09.670270Z",
     "start_time": "2020-04-13T04:17:55.540Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def info_batch(info):\n",
    "    with open('info_de.pkl', 'ab') as fp: \n",
    "        pickle.dump(info, fp) \n",
    "    \n",
    "def exp_batch(exp):\n",
    "    with open('exp_de.pkl', 'ab') as fp:\n",
    "        pickle.dump(exp, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-13T04:53:09.673601Z",
     "start_time": "2020-04-13T04:17:56.283Z"
    }
   },
   "outputs": [],
   "source": [
    "LI_AT = 'AQEDASninKgFCQENAAABcWJ8RbkAAAFxhojJuU0ARn_JC06BmSzB8515Xro1AqXinajR4vaRFt5_RFnE1Yc9_6F1VWCAS9BjkPnfqHkirT9j3Mjdb_U0JpJ8EDgfItrqRsndIjAMxyTc0LqheG64WKPJ'\n",
    "\n",
    "\n",
    "for name in name_ds:\n",
    "    with ProfileScraper(cookie = LI_AT) as scraper:\n",
    "        profile = scraper.scrape(user = name)\n",
    "        \n",
    "    # save to info file        \n",
    "    summary = profile.personal_info['summary']\n",
    "    skill = [profile.skills[i]['name'] for i in range(len(profile.skills))]\n",
    "    certi = profile.accomplishments['certifications']\n",
    "    course = profile.accomplishments['courses']\n",
    "\n",
    "    info_batch(tuple([name, summary, skill, course, certi]))\n",
    "    \n",
    "    # save to exp file\n",
    "    for job in profile.experiences['jobs']:\n",
    "        exp_batch(tuple([name, job['title'], job['company'], job['date_range'], job['location'], job['description']]))\n",
    "    print(name)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert pickle to csv\n",
    "## Information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-15T13:29:21.725942Z",
     "start_time": "2020-04-15T13:29:21.682903Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>skill</th>\n",
       "      <th>course</th>\n",
       "      <th>certi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ming-li-m-s-aws-csa-aws-adev-69b5a342</td>\n",
       "      <td></td>\n",
       "      <td>[SQL, C, Python, C#, Linux, JavaScript, Scala,...</td>\n",
       "      <td>[AWS System Implementation, C/C++ Language Pro...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frederick-kirwin</td>\n",
       "      <td>QUERY/PROGRAMMING LANGUAGES: SQL, T-SQL, Pytho...</td>\n",
       "      <td>[Data Analysis, Business Intelligence, Databas...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jonathan-kaczynski-011a623</td>\n",
       "      <td>I am a generalist developer focused on buildin...</td>\n",
       "      <td>[Ruby, Python, Ruby on Rails, Java, Git, Linux...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toddeanderson</td>\n",
       "      <td>Recent experience as Data Engineer/Analyst usi...</td>\n",
       "      <td>[Software Development, Databases, Perl]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>david-choy-8659a614</td>\n",
       "      <td>Google Cloud: Storage, Dataproc and Big QueryB...</td>\n",
       "      <td>[Databases, Microsoft SQL Server, Data Warehou...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>sruthirajagopal</td>\n",
       "      <td>Data engineer with 7 years of experience in da...</td>\n",
       "      <td>[SQL, Java, Data Warehousing, Microsoft SQL Se...</td>\n",
       "      <td>[Data Analysis, Data Modelling, Data Visualiza...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>paromitas</td>\n",
       "      <td>Senior Data Engineer with over 13 years of exp...</td>\n",
       "      <td>[Microsoft SQL Server, SQL, Databases, T-SQL, ...</td>\n",
       "      <td>[GNIIT]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>blane07</td>\n",
       "      <td></td>\n",
       "      <td>[Leadership, Data Science, Engineering, Python...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>weytu</td>\n",
       "      <td>A dreamer, hustler, blogger, coder, lifetime l...</td>\n",
       "      <td>[Deep Learning, Machine Learning, Python, Team...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>xia-wang-b68b957a</td>\n",
       "      <td>I'm a data engineer at rocketmiles.com. I orch...</td>\n",
       "      <td>[Python, Spanish, SQL, Linguistics, Research, ...</td>\n",
       "      <td>[Applied Data Science, Big Data Management and...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      name  \\\n",
       "0    ming-li-m-s-aws-csa-aws-adev-69b5a342   \n",
       "1                         frederick-kirwin   \n",
       "2               jonathan-kaczynski-011a623   \n",
       "3                            toddeanderson   \n",
       "4                      david-choy-8659a614   \n",
       "..                                     ...   \n",
       "533                        sruthirajagopal   \n",
       "534                              paromitas   \n",
       "535                                blane07   \n",
       "536                                  weytu   \n",
       "537                      xia-wang-b68b957a   \n",
       "\n",
       "                                               summary  \\\n",
       "0                                                        \n",
       "1    QUERY/PROGRAMMING LANGUAGES: SQL, T-SQL, Pytho...   \n",
       "2    I am a generalist developer focused on buildin...   \n",
       "3    Recent experience as Data Engineer/Analyst usi...   \n",
       "4    Google Cloud: Storage, Dataproc and Big QueryB...   \n",
       "..                                                 ...   \n",
       "533  Data engineer with 7 years of experience in da...   \n",
       "534  Senior Data Engineer with over 13 years of exp...   \n",
       "535                                                      \n",
       "536  A dreamer, hustler, blogger, coder, lifetime l...   \n",
       "537  I'm a data engineer at rocketmiles.com. I orch...   \n",
       "\n",
       "                                                 skill  \\\n",
       "0    [SQL, C, Python, C#, Linux, JavaScript, Scala,...   \n",
       "1    [Data Analysis, Business Intelligence, Databas...   \n",
       "2    [Ruby, Python, Ruby on Rails, Java, Git, Linux...   \n",
       "3              [Software Development, Databases, Perl]   \n",
       "4    [Databases, Microsoft SQL Server, Data Warehou...   \n",
       "..                                                 ...   \n",
       "533  [SQL, Java, Data Warehousing, Microsoft SQL Se...   \n",
       "534  [Microsoft SQL Server, SQL, Databases, T-SQL, ...   \n",
       "535  [Leadership, Data Science, Engineering, Python...   \n",
       "536  [Deep Learning, Machine Learning, Python, Team...   \n",
       "537  [Python, Spanish, SQL, Linguistics, Research, ...   \n",
       "\n",
       "                                                course certi  \n",
       "0    [AWS System Implementation, C/C++ Language Pro...    []  \n",
       "1                                                   []    []  \n",
       "2                                                   []    []  \n",
       "3                                                   []    []  \n",
       "4                                                   []    []  \n",
       "..                                                 ...   ...  \n",
       "533  [Data Analysis, Data Modelling, Data Visualiza...    []  \n",
       "534                                            [GNIIT]    []  \n",
       "535                                                 []    []  \n",
       "536                                                 []    []  \n",
       "537  [Applied Data Science, Big Data Management and...    []  \n",
       "\n",
       "[538 rows x 5 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call info pickle file\n",
    "colnames = ['name', 'summary', 'skill', 'course', 'certi']\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "info = []\n",
    "with open('info_de.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            info.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "info_df = pd.DataFrame(info, columns=colnames)\n",
    "info_df\n",
    "# info_df.to_csv('info.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T21:51:35.557913Z",
     "start_time": "2020-06-07T21:51:35.486956Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>date_range</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ming-li-m-s-aws-csa-aws-adev-69b5a342</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Meredith Corporation</td>\n",
       "      <td>Sep 2018 – Present</td>\n",
       "      <td>Des Moines, Iowa Area</td>\n",
       "      <td>Work with Meredith core profile team processin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ming-li-m-s-aws-csa-aws-adev-69b5a342</td>\n",
       "      <td>System Engineer</td>\n",
       "      <td>The Karcher group</td>\n",
       "      <td>May 2015 – Aug 2018</td>\n",
       "      <td>Chantilly</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ming-li-m-s-aws-csa-aws-adev-69b5a342</td>\n",
       "      <td>Software Developer</td>\n",
       "      <td>ABC Imaging</td>\n",
       "      <td>May 2014 – Mar 2015</td>\n",
       "      <td>Washington D.C. Metro Area</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ming-li-m-s-aws-csa-aws-adev-69b5a342</td>\n",
       "      <td>Application Developer</td>\n",
       "      <td>University of Maryland College Park</td>\n",
       "      <td>Nov 2011 – Oct 2013</td>\n",
       "      <td>College Park, MD</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ming-li-m-s-aws-csa-aws-adev-69b5a342</td>\n",
       "      <td>Network Engineer</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Jun 2010 – Aug 2011</td>\n",
       "      <td>Dalian, Liaoning, China</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Jan 2019 – Present</td>\n",
       "      <td>None</td>\n",
       "      <td>Building/Optimizing the warehousing and report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>VideoAmp</td>\n",
       "      <td>Jun 2018 – Jan 2019</td>\n",
       "      <td>Santa Monica, California</td>\n",
       "      <td>Bringing simplicity to complex Ad-tech data on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Student Tech Admin</td>\n",
       "      <td>California State University-Long Beach</td>\n",
       "      <td>Oct 2016 – Jun 2018</td>\n",
       "      <td>Greater Los Angeles Area</td>\n",
       "      <td>i. Sys-Ops, responsible for server configurati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7006</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>CrowdANALYTIX</td>\n",
       "      <td>Dec 2015 – Aug 2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>i. Text Mining / Automated Product Cataloging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7007</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Just Dial Limited</td>\n",
       "      <td>Jul 2014 – Dec 2015</td>\n",
       "      <td>Mumbai Area, India</td>\n",
       "      <td>DevOps / Web-crawling / ETL:i. Developed over ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7008 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name                  title  \\\n",
       "0     ming-li-m-s-aws-csa-aws-adev-69b5a342          Data Engineer   \n",
       "1     ming-li-m-s-aws-csa-aws-adev-69b5a342        System Engineer   \n",
       "2     ming-li-m-s-aws-csa-aws-adev-69b5a342     Software Developer   \n",
       "3     ming-li-m-s-aws-csa-aws-adev-69b5a342  Application Developer   \n",
       "4     ming-li-m-s-aws-csa-aws-adev-69b5a342       Network Engineer   \n",
       "...                                     ...                    ...   \n",
       "7003                              hemanthbm          Data Engineer   \n",
       "7004                              hemanthbm          Data Engineer   \n",
       "7005                              hemanthbm     Student Tech Admin   \n",
       "7006                              hemanthbm          Data Engineer   \n",
       "7007                              hemanthbm      Software Engineer   \n",
       "\n",
       "                                     company           date_range  \\\n",
       "0                       Meredith Corporation   Sep 2018 – Present   \n",
       "1                          The Karcher group  May 2015 – Aug 2018   \n",
       "2                                ABC Imaging  May 2014 – Mar 2015   \n",
       "3        University of Maryland College Park  Nov 2011 – Oct 2013   \n",
       "4                                        IBM  Jun 2010 – Aug 2011   \n",
       "...                                      ...                  ...   \n",
       "7003                            Walmart Labs   Jan 2019 – Present   \n",
       "7004                                VideoAmp  Jun 2018 – Jan 2019   \n",
       "7005  California State University-Long Beach  Oct 2016 – Jun 2018   \n",
       "7006                           CrowdANALYTIX  Dec 2015 – Aug 2016   \n",
       "7007                       Just Dial Limited  Jul 2014 – Dec 2015   \n",
       "\n",
       "                        location  \\\n",
       "0          Des Moines, Iowa Area   \n",
       "1                      Chantilly   \n",
       "2     Washington D.C. Metro Area   \n",
       "3               College Park, MD   \n",
       "4        Dalian, Liaoning, China   \n",
       "...                          ...   \n",
       "7003                        None   \n",
       "7004    Santa Monica, California   \n",
       "7005    Greater Los Angeles Area   \n",
       "7006                   Bangalore   \n",
       "7007          Mumbai Area, India   \n",
       "\n",
       "                                            description  \n",
       "0     Work with Meredith core profile team processin...  \n",
       "1                                                  None  \n",
       "2                                                  None  \n",
       "3                                                  None  \n",
       "4                                                  None  \n",
       "...                                                 ...  \n",
       "7003  Building/Optimizing the warehousing and report...  \n",
       "7004  Bringing simplicity to complex Ad-tech data on...  \n",
       "7005  i. Sys-Ops, responsible for server configurati...  \n",
       "7006  i. Text Mining / Automated Product Cataloging ...  \n",
       "7007  DevOps / Web-crawling / ETL:i. Developed over ...  \n",
       "\n",
       "[7008 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call exp pickle file\n",
    "colnames = ['name', 'title', 'company', 'date_range', 'location', 'description']\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "exp = []\n",
    "with open('exp_de.pkl', 'rb') as fr:\n",
    "    try:\n",
    "        while True:\n",
    "            exp.append(pickle.load(fr))\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "exp_df = pd.DataFrame(exp, columns=colnames)\n",
    "exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T21:52:22.483006Z",
     "start_time": "2020-06-07T21:52:22.441332Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_df.dropna(subset = ['description'], inplace = True)\n",
    "exp_df.drop_duplicates(inplace = True)\n",
    "exp_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T21:53:01.467020Z",
     "start_time": "2020-06-07T21:53:01.360161Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_df.to_csv('exp_de.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.drop_dupplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T21:52:48.616629Z",
     "start_time": "2020-06-07T21:52:48.611978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4758, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T21:53:05.595045Z",
     "start_time": "2020-06-07T21:53:05.536424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>date_range</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ming-li-m-s-aws-csa-aws-adev-69b5a342</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Meredith Corporation</td>\n",
       "      <td>Sep 2018 – Present</td>\n",
       "      <td>Des Moines, Iowa Area</td>\n",
       "      <td>Work with Meredith core profile team processin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frederick-kirwin</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Aetna, a CVS Health Company\\n        Full-time</td>\n",
       "      <td>Feb 2019 – Present</td>\n",
       "      <td>Hartford, Connecticut Area</td>\n",
       "      <td>Build real time and batch big data application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frederick-kirwin</td>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>3M</td>\n",
       "      <td>Jun 2016 – Feb 2019</td>\n",
       "      <td>Wallingford, CT</td>\n",
       "      <td>•\\tWork with Analysts, Architects, Modelers an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frederick-kirwin</td>\n",
       "      <td>Data Management</td>\n",
       "      <td>Mediassociates</td>\n",
       "      <td>Sep 2015 – May 2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>•\\tArchitect and design custom databases to en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frederick-kirwin</td>\n",
       "      <td>Data Warehouse Analyst</td>\n",
       "      <td>Centrix Inc.</td>\n",
       "      <td>Apr 2015 – Aug 2015</td>\n",
       "      <td>Shelton, CT</td>\n",
       "      <td>•\\tWork with SSRS, SSAS, SSIS and T-SQL querie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>Jan 2019 – Present</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Building/Optimizing the warehousing and report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>VideoAmp</td>\n",
       "      <td>Jun 2018 – Jan 2019</td>\n",
       "      <td>Santa Monica, California</td>\n",
       "      <td>Bringing simplicity to complex Ad-tech data on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Student Tech Admin</td>\n",
       "      <td>California State University-Long Beach</td>\n",
       "      <td>Oct 2016 – Jun 2018</td>\n",
       "      <td>Greater Los Angeles Area</td>\n",
       "      <td>i. Sys-Ops, responsible for server configurati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>CrowdANALYTIX</td>\n",
       "      <td>Dec 2015 – Aug 2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>i. Text Mining / Automated Product Cataloging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>hemanthbm</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Just Dial Limited</td>\n",
       "      <td>Jul 2014 – Dec 2015</td>\n",
       "      <td>Mumbai Area, India</td>\n",
       "      <td>DevOps / Web-crawling / ETL:i. Developed over ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4758 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name                     title  \\\n",
       "0     ming-li-m-s-aws-csa-aws-adev-69b5a342             Data Engineer   \n",
       "1                          frederick-kirwin        Lead Data Engineer   \n",
       "2                          frederick-kirwin  Senior Software Engineer   \n",
       "3                          frederick-kirwin           Data Management   \n",
       "4                          frederick-kirwin    Data Warehouse Analyst   \n",
       "...                                     ...                       ...   \n",
       "4753                              hemanthbm             Data Engineer   \n",
       "4754                              hemanthbm             Data Engineer   \n",
       "4755                              hemanthbm        Student Tech Admin   \n",
       "4756                              hemanthbm             Data Engineer   \n",
       "4757                              hemanthbm         Software Engineer   \n",
       "\n",
       "                                             company           date_range  \\\n",
       "0                               Meredith Corporation   Sep 2018 – Present   \n",
       "1     Aetna, a CVS Health Company\\n        Full-time   Feb 2019 – Present   \n",
       "2                                                 3M  Jun 2016 – Feb 2019   \n",
       "3                                     Mediassociates  Sep 2015 – May 2016   \n",
       "4                                       Centrix Inc.  Apr 2015 – Aug 2015   \n",
       "...                                              ...                  ...   \n",
       "4753                                    Walmart Labs   Jan 2019 – Present   \n",
       "4754                                        VideoAmp  Jun 2018 – Jan 2019   \n",
       "4755          California State University-Long Beach  Oct 2016 – Jun 2018   \n",
       "4756                                   CrowdANALYTIX  Dec 2015 – Aug 2016   \n",
       "4757                               Just Dial Limited  Jul 2014 – Dec 2015   \n",
       "\n",
       "                        location  \\\n",
       "0          Des Moines, Iowa Area   \n",
       "1     Hartford, Connecticut Area   \n",
       "2                Wallingford, CT   \n",
       "3                            NaN   \n",
       "4                    Shelton, CT   \n",
       "...                          ...   \n",
       "4753                         NaN   \n",
       "4754    Santa Monica, California   \n",
       "4755    Greater Los Angeles Area   \n",
       "4756                   Bangalore   \n",
       "4757          Mumbai Area, India   \n",
       "\n",
       "                                            description  \n",
       "0     Work with Meredith core profile team processin...  \n",
       "1     Build real time and batch big data application...  \n",
       "2     •\\tWork with Analysts, Architects, Modelers an...  \n",
       "3     •\\tArchitect and design custom databases to en...  \n",
       "4     •\\tWork with SSRS, SSAS, SSIS and T-SQL querie...  \n",
       "...                                                 ...  \n",
       "4753  Building/Optimizing the warehousing and report...  \n",
       "4754  Bringing simplicity to complex Ad-tech data on...  \n",
       "4755  i. Sys-Ops, responsible for server configurati...  \n",
       "4756  i. Text Mining / Automated Product Cataloging ...  \n",
       "4757  DevOps / Web-crawling / ETL:i. Developed over ...  \n",
       "\n",
       "[4758 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('exp_de.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T03:44:02.980510Z",
     "start_time": "2020-04-14T03:44:02.972402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 6)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T03:45:41.774219Z",
     "start_time": "2020-04-14T03:45:41.768061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTeach Android Application Development to graduate and undergraduates, patiently help them in understanding and debugging their applications.Teaching Assistant for C++ Programming Language.\\nAssist Students in the Programming \\nEnsure that students understand and implement the logic behind programming.\\nAssisted instructor in developing exam metrics and student performance metrics.\\nEvaluate assignments, quizzes, and exams.\\n'"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T03:45:41.350863Z",
     "start_time": "2020-04-14T03:45:41.339881Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# s = re.sub('([\\-\\*\\•\\○]\\s)|(\\n\\n\\s+\\n…\\n\\n\\s+see more$)', \"\\n\", s)\n",
    "s = re.sub('[-*○•●]\\s|•\\t|●\\t|\\uf0b7|•|\\x95|\\n\\n    \\n…\\n\\n        see more$', '\\n', s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T03:45:25.280985Z",
     "start_time": "2020-04-14T03:45:25.274498Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'•Teach Android Application Development to graduate and undergraduates, patiently help them in understanding and debugging their applications.Teaching Assistant for C++ Programming Language.•\\tAssist Students in the Programming •\\tEnsure that students understand and implement the logic behind programming.•\\tAssisted instructor in developing exam metrics and student performance metrics.•\\tEvaluate assignments, quizzes, and exams.\\n\\n    \\n…\\n\\n        see more'"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "r = random.randint(0, 561)\n",
    "s = exp_df['description'][r]\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
